# Step 1: Import Libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.cluster import KMeans
import nltk
from nltk.corpus import stopwords
import matplotlib.pyplot as plt
import seaborn as sns

# Download stopwords if not downloaded
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Step 2: Load Dataset (Sample Data)
data = {
    'label': ['ham', 'spam', 'ham', 'spam', 'ham'],
    'message': [
        "Hi how are you?",
        "Congratulations! You won a free ticket",
        "Let's meet tomorrow",
        "You have won $1000 cash prize!!!",
        "Are you coming to the party?"
    ]
}
df = pd.DataFrame(data)

# Step 3: Preprocessing
def preprocess(text):
    words = text.lower().split()
    filtered = [word for word in words if word not in stop_words]
    return " ".join(filtered)

df['cleaned'] = df['message'].apply(preprocess)

# Step 4: Feature Extraction
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['cleaned'])
y = df['label']

# Step 5: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Model (Naive Bayes)
model = MultinomialNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Step 7: Performance Measures
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Step 8: Clustering (KMeans - Simple Demo)
kmeans = KMeans(n_clusters=2, random_state=42)
clusters = kmeans.fit_predict(X.toarray())
df['cluster'] = clusters
print("\nClustered Data:")
print(df[['message', 'label', 'cluster']])
